<!DOCTYPE html>
<html>
<head>
  <title>表情管理アプリケーション</title>
  <!-- Chart.jsのスクリプトを追加 -->
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
</head>
<body>
  <video id="video" width="640" height="480" autoplay></video>
  <canvas id="canvas" width="640" height="480"></canvas>
  <!-- グラフを表示するためのCanvas要素 -->
  <canvas id="emotionChart" width="400" height="200"></canvas>

  <script>
    // ページの読み込みが完了したら実行
    window.onload = function() {
      const video = document.getElementById('video');
      const canvas = document.getElementById('canvas');
      const ctx = canvas.getContext('2d');
      const resultDiv = document.getElementById('result');

      // Webカメラの利用許可を取得
      navigator.mediaDevices.getUserMedia({ video: true })
        .then((stream) => {
          video.srcObject = stream;
        })
        .catch((error) => {
          console.error('Webカメラの利用許可がありません。', error);
        });

      // Microsoft Emotion APIのエンドポイントとサブスクリプションキー
      const endpoint = 'https://westcentralus.api.cognitive.microsoft.com/face/v1.0/detect';
      const apiKey = 'YOUR_EMOTION_API_KEY'; // ここをEmotion APIのキーに置き換える

      // Chart.jsを初期化
      const ctxChart = document.getElementById('emotionChart').getContext('2d');
      const emotionChart = new Chart(ctxChart, {
        type: 'bar',
        data: {
          labels: ['笑顔', '悲しい顔'],
          datasets: [{
            label: '表情スコア',
            data: [0, 0], // 初期値は0
            backgroundColor: [
              'rgba(75, 192, 192, 0.2)',
              'rgba(255, 99, 132, 0.2)',
            ],
            borderColor: [
              'rgba(75, 192, 192, 1)',
              'rgba(255, 99, 132, 1)',
            ],
            borderWidth: 1
          }]
        },
        options: {
          scales: {
            y: {
              beginAtZero: true
            }
          }
        }
      });

      // フレームごとに表情を取得する関数
      function detectEmotion() {
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        const image = canvas.toDataURL('image/jpeg');

        // Emotion APIにリクエストを送信
        fetch(endpoint + '?returnFaceAttributes=emotion', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Ocp-Apim-Subscription-Key': apiKey,
          },
          body: JSON.stringify({ url: image }),
        })
          .then((response) => response.json())
          .then((data) => {
            if (data && data.length > 0) {
              const emotions = data[0].faceAttributes.emotion;
              const { happiness, sadness } = emotions;

              // グラフを更新して表情スコアを表示
              emotionChart.data.datasets[0].data = [happiness, sadness];
              emotionChart.update();

              // 表情スコアをテキストとして表示
              resultDiv.innerHTML = `
                <p>笑顔: ${happiness}</p>
                <p>悲しい顔: ${sadness}</p>
              `;
            }
          })
          .catch((error) => {
            console.error('Emotion APIのリクエストに失敗しました。', error);
          });

        // 1000msごとに表情を取得
        setTimeout(detectEmotion, 1000);
      }

      // 表情を取得する関数を実行
      detectEmotion();
    };
  </script>
</body>
</html>
